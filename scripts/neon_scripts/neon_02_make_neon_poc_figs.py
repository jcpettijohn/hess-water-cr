#!/usr/bin/env python3
"""
NEON proof-of-concept: filter, bin, and make manuscript-aligned figures from daily_cr_demo.csv.

This script expects the daily CSV produced by neon_01_make_cr_plots_PM.py and creates:

1) "Vanilla" CR plot (classical form):
   λE, λE_pa, λE_p0 vs a moisture-availability proxy inferred from y (and mapped to r_s/r_a).
   This mirrors the manuscript's conceptual CR figure structure, but uses NEON-derived daily values.

2) x–y "atlas" coordinates:
   y = E / E_pa
   x = E_p0 / E_pa
   plotted for two E_p0 constructions (α=1 and α=α_PT), with horizontal connection lines.

3) QC plot:
   E vs E_pa with 1:1 line (helps diagnose y>1 issues).

Notes on interpretation:
- In the manuscript-consistent PM structure, if the observed evaporation were exactly described by
  PM with r_s >= 0 using the same (Rn-G, VPD, r_a), then y should be <= 1. Values y>1 usually
  indicate (i) E_pa underestimated (heights/units/aggregation), (ii) energy-balance issues, or
  (iii) local advection/source-area mismatch.

Author: (generated by ChatGPT)
"""
from __future__ import annotations

import argparse
import math
import sys
from pathlib import Path
from typing import Optional, Sequence, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# keep consistent with script 01
CP_AIR = 1004.0
EPSILON = 0.622

def sat_vp_kpa(T_C: np.ndarray) -> np.ndarray:
    return 0.6108 * np.exp((17.27 * T_C) / (T_C + 237.3))

def slope_sat_vp_curve_kpa_per_C(T_C: np.ndarray) -> np.ndarray:
    es = sat_vp_kpa(T_C)
    return 4098.0 * es / np.square(T_C + 237.3)

def latent_heat_vaporization_J_per_kg(T_C: np.ndarray) -> np.ndarray:
    return 2.501e6 - 2370.0 * T_C

def psychrometric_constant_kpa_per_C(p_kpa: np.ndarray, lam_J_kg: np.ndarray) -> np.ndarray:
    return (CP_AIR * p_kpa) / (EPSILON * lam_J_kg)

def implied_rs_over_ra_from_y(y: np.ndarray, Delta: np.ndarray, gamma: np.ndarray) -> np.ndarray:
    """
    From PM structure with shared numerator:
        y = (Δ+γ) / (Δ + γ(1 + r_s/r_a))
          = (Δ+γ) / (Δ+γ + γ r_s/r_a)

    => r_s/r_a = (Δ+γ)/γ * (1/y - 1)
    """
    y = np.array(y, dtype=float)
    k = (Delta + gamma) / np.maximum(gamma, 1e-12)
    phi = k * (1.0 / np.maximum(y, 1e-12) - 1.0)
    return phi

def mj_day_to_wm2(mj_day: np.ndarray) -> np.ndarray:
    """Convert MJ m-2 d-1 to W m-2 using 86400 s/day and 1e6 J/MJ."""
    return (np.array(mj_day, dtype=float) * 1e6) / 86400.0

def robust_slope_through_origin(x: np.ndarray, y: np.ndarray) -> float:
    """Least-squares slope through origin (safe)."""
    x = np.array(x, dtype=float)
    y = np.array(y, dtype=float)
    m = np.isfinite(x) & np.isfinite(y)
    x = x[m]; y = y[m]
    if len(x) < 3:
        return float("nan")
    denom = np.sum(x * x)
    if denom <= 0:
        return float("nan")
    return float(np.sum(x * y) / denom)

def parse_args(argv: Optional[Sequence[str]] = None) -> argparse.Namespace:
    ap = argparse.ArgumentParser(description="Filter/bin NEON daily CR data and make manuscript-aligned figures.")
    ap.add_argument("--csv", type=str, default=None, help="Path to daily_cr_demo.csv (defaults from --root/--site/--start/--end).")
    ap.add_argument("--root", type=str, default="data/neon")
    ap.add_argument("--site", type=str, required=True)
    ap.add_argument("--start", type=str, required=True)
    ap.add_argument("--end", type=str, required=True)
    ap.add_argument("--outdir", type=str, default=None, help="Where to write figures (defaults to site folder /figures).")

    ap.add_argument("--min-coverage", type=float, default=0.8)
    ap.add_argument("--y-max", type=float, default=1.2, help="Filter out days with y above this (QC).")
    ap.add_argument("--bins", type=int, default=10, help="Number of bins for the vanilla CR plot.")
    ap.add_argument("--min-bin-n", type=int, default=3, help="Minimum sample count per bin for the vanilla CR plot. The script will automatically reduce the number of bins so that ~min-bin-n points fall in each bin.")
    # NOTE: argparse uses old-style %-formatting for help strings (to expand %(default)s etc).
    # Any literal percent signs must be escaped as %% (or spelled out as "percent").
    ap.add_argument(
        "--outlier-p",
        type=float,
        default=0.0,
        help=(
            "Optional quantile trim to suppress outliers in daily diagnostics. "
            "Set to e.g. 0.01 to drop the lowest/highest 1 percent in key variables. "
            "0 disables."
        ),
    )
    return ap.parse_args(argv)

def main(argv: Optional[Sequence[str]] = None) -> int:
    args = parse_args(argv)

    site_tag = f"{args.site}_{args.start}_{args.end}"
    base = Path(args.root) / site_tag
    csv_path = Path(args.csv) if args.csv else (base / "daily_cr_demo.csv")
    if not csv_path.exists():
        raise FileNotFoundError(f"Daily CSV not found: {csv_path}")

    outdir = Path(args.outdir) if args.outdir else (base / "figures")
    outdir.mkdir(parents=True, exist_ok=True)

    df = pd.read_csv(csv_path)
    df["date"] = pd.to_datetime(df["date"], utc=True)

    # basic filters
    df["good"] = df.get("good_day", True)
    df["good"] &= df["coverage"] >= float(args.min_coverage)
    df["good"] &= np.isfinite(df["y"]) & np.isfinite(df["x_eq"]) & np.isfinite(df["x_PT"])
    df["good"] &= df["LE_pa_MJ_d"] > 0
    df["good"] &= df["y"] > 0
    df["good"] &= df["y"] <= float(args.y_max)

    good = df[df["good"]].copy()
    # Optional: drop extreme outliers (helps figures when a few days dominate the scaling).
    if float(args.outlier_p) > 0 and len(good) >= 10:
        ptrim = float(args.outlier_p)
        ptrim = min(max(ptrim, 0.0), 0.49)
        key_cols = [c for c in ["y","x_eq","x_PT","E_mm_d","Epa_mm_d","Ep0eq_mm_d","Ep0PT_mm_d","RnG_MJ_d","u_ms"] if c in good.columns]
        m_keep = np.ones(len(good), dtype=bool)
        for c in key_cols:
            v = pd.to_numeric(good[c], errors="coerce").to_numpy(dtype=float)
            if np.all(~np.isfinite(v)):
                continue
            lo, hi = np.nanquantile(v, [ptrim, 1.0 - ptrim])
            m_keep &= np.isfinite(v) & (v >= lo) & (v <= hi)
        good = good[m_keep].copy()
        if len(good) < 5:
            print("WARNING: outlier trimming left very few days; consider using --outlier-p 0 or a longer date range.", file=sys.stderr)
    if len(good) < 5:
        print("WARNING: very few good days after filtering; figures may be sparse.", file=sys.stderr)

    # compute implied r_s/r_a (diagnostic moisture coordinate) using daily-mean Delta,gamma
    T = good["T_C"].to_numpy()
    p = good["p_kPa"].to_numpy()
    lam = latent_heat_vaporization_J_per_kg(T)
    Delta = slope_sat_vp_curve_kpa_per_C(T)
    gamma = psychrometric_constant_kpa_per_C(p, lam)
    good["phi_rs_ra"] = implied_rs_over_ra_from_y(good["y"].to_numpy(), Delta, gamma)

    # moisture proxy in [0,1]: M = 1/(1+phi) (wet -> 1, dry -> 0)
    good["M_proxy"] = 1.0 / (1.0 + np.maximum(good["phi_rs_ra"], 0.0))

    # -------------------------
    # Figure 1: x-y definition shift
    # -------------------------
    fig1 = plt.figure(figsize=(8, 6), dpi=200)
    ax = fig1.add_subplot(111)

    # thin connectors (horizontal shifts)
    for _, r in good.iterrows():
        ax.plot([r["x_eq"], r["x_PT"]], [r["y"], r["y"]], linewidth=0.6, alpha=0.2)

    ax.scatter(good["x_eq"], good["y"], s=18, label="(x_eq, y)  α=1", alpha=0.9)
    ax.scatter(good["x_PT"], good["y"], s=18, label="(x_PT, y)  α=1.26", alpha=0.9)

    ax.axhline(1.0, linewidth=1.0)
    ax.axvline(1.0, linewidth=1.0)
    ax.set_xlabel("x = Ep0 / Epa")
    ax.set_ylabel("y = E / Epa")
    ax.set_title(f"NEON {args.site}: definition sensitivity shifts x (good days)")

    # annotate typical shift
    dx = np.nanmedian(good["x_PT"] - good["x_eq"]) if len(good) else float("nan")
    ax.text(0.02, 0.02, f"median Δx = x_PT - x_eq = {dx:.3f}", transform=ax.transAxes)

    ax.legend(frameon=True)
    fig1.tight_layout()
    f1 = outdir / "fig_neon_xy_definition_shift_good.png"
    fig1.savefig(f1)
    plt.close(fig1)

    # -------------------------
    # Figure 2: vanilla CR plot (binned curves) vs moisture proxy
    # -------------------------
    fig2 = plt.figure(figsize=(8, 5.5), dpi=200)
    ax2 = fig2.add_subplot(111)

    # bins in M_proxy
    M = good["M_proxy"].to_numpy()
    # guard
    M = np.clip(M, 0.0, 1.0)
    good = good.assign(M_proxy=M)

    # Choose a bin count that is compatible with the number of available days.
    # If you ask for too many bins (relative to sample size), every bin has ~1--2 points and the
    # median/IQR curves become all-NaN (blank plot). We therefore cap the effective bin count so that
    # we have roughly `min_bin_n` samples per bin.
    bins_req = int(args.bins)
    min_bin_n = max(1, int(args.min_bin_n))
    n_days = int(len(M))
    bins_max = max(1, int(np.floor(n_days / float(min_bin_n))))  # e.g., 20 days, min_bin_n=3 -> <=6 bins
    bins = max(1, min(bins_req, bins_max))

    # Quantile bins (more stable than equal-width when the site samples a narrow range)
    q = np.linspace(0.0, 1.0, bins + 1)
    edges = np.quantile(M, q)

    # ensure strictly increasing bin edges
    edges = np.unique(edges)

    # If the data are too degenerate (all M nearly identical), fall back to [0,1]
    if len(edges) < 2:
        edges = np.array([0.0, 1.0])

    bins_eff = len(edges) - 1
    if bins_eff < 1:
        edges = np.array([0.0, 1.0])
        bins_eff = 1
    if bins_eff != bins:
        bins = bins_eff


    def bin_stat(arr: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        med = np.full(bins, np.nan)
        p25 = np.full(bins, np.nan)
        p75 = np.full(bins, np.nan)
        for i in range(bins):
            m = (M >= edges[i]) & (M < edges[i+1]) if i < bins-1 else (M >= edges[i]) & (M <= edges[i+1])
            if np.sum(m) >= 1:
                med[i] = np.nanmedian(arr[m])
                p25[i] = np.nanpercentile(arr[m], 25)
                p75[i] = np.nanpercentile(arr[m], 75)
        return med, p25, p75

    # Use daily-mean latent heat fluxes in W/m2 for plotting
    LE = mj_day_to_wm2(good["LE_obs_MJ_d"].to_numpy())
    LEpa = mj_day_to_wm2(good["LE_pa_MJ_d"].to_numpy())
    LEp0eq = mj_day_to_wm2(good["LE_p0_eq_MJ_d"].to_numpy())
    LEp0pt = mj_day_to_wm2(good["LE_p0_PT_MJ_d"].to_numpy())

    for series, lab in [
        (LE, "λE (observed)"),
        (LEpa, "λEpa (PM, r_s=0)"),
        (LEp0eq, "λEp0 (equilibrium, α=1)"),
        (LEp0pt, "λEp0 (Priestley–Taylor, α=1.26)"),
    ]:
        med, p25, p75 = bin_stat(series)
        centers = 0.5 * (edges[:-1] + edges[1:])
        ax2.plot(centers, med, linewidth=2.2, label=lab)
        # IQR shading
        ax2.fill_between(centers, p25, p75, alpha=0.15)

    ax2.set_xlabel("Moisture availability proxy  M  (wet → 1)")
    ax2.set_ylabel("Daily mean latent heat flux  λE  (W m$^{-2}$)")
    ax2.set_title(f"NEON {args.site}: vanilla CR plot (binned by implied r_s/r_a)")
    ax2.legend(frameon=True)
    fig2.tight_layout()
    f2 = outdir / "fig_neon_vanilla_CR_binned.png"
    fig2.savefig(f2)
    plt.close(fig2)

    # -------------------------
    # Figure 3: QC (E vs Epa)
    # -------------------------
    fig3 = plt.figure(figsize=(6.2, 6.2), dpi=200)
    ax3 = fig3.add_subplot(111)

    # Use mm/day for intuitive axis (still okay)
    ax3.scatter(good["Epa_mm_d"], good["E_mm_d"], s=18, alpha=0.8)
    maxv = np.nanmax([good["Epa_mm_d"].max(), good["E_mm_d"].max()]) if len(good) else 1.0
    ax3.plot([0, maxv], [0, maxv], linewidth=1.0)
    ax3.set_xlabel("Epa (mm d$^{-1}$)")
    ax3.set_ylabel("E (mm d$^{-1}$)")
    ax3.set_title(f"NEON {args.site}: QC E vs Epa (good days)")
    fig3.tight_layout()
    f3 = outdir / "fig_neon_qc_E_vs_Epa.png"
    fig3.savefig(f3)
    plt.close(fig3)

    # -------------------------
    # Figure 4: complementarity plane b (optional; purely diagnostic)
    # -------------------------
    # Epa - Ep0 vs Ep0 - E  => slope b (through origin)
    # Use mm/day for readability
    fig4 = plt.figure(figsize=(7.2, 5.6), dpi=200)
    ax4 = fig4.add_subplot(111)

    for key, lab in [("eq", "Ep0 (α=1)"), ("PT", "Ep0 (α=1.26)")]:
        Ep0 = good["Ep0eq_mm_d"].to_numpy() if key == "eq" else good["Ep0PT_mm_d"].to_numpy()
        Epa = good["Epa_mm_d"].to_numpy()
        E = good["E_mm_d"].to_numpy()
        x = Ep0 - E
        y = Epa - Ep0
        # keep physically typical quadrant for b estimation
        m = np.isfinite(x) & np.isfinite(y) & (x > 0) & (y > 0)
        b = robust_slope_through_origin(x[m], y[m])
        ax4.scatter(x, y, s=18, alpha=0.75, label=f"{lab}, b≈{b:.2f}")
        # plot the slope line over the data range
        if np.isfinite(b) and np.sum(m) >= 5:
            xx = np.linspace(0, np.nanpercentile(x[m], 95), 50)
            ax4.plot(xx, b * xx, linewidth=2.0)

    ax4.set_xlabel("Ep0 − E (mm d$^{-1}$)")
    ax4.set_ylabel("Epa − Ep0 (mm d$^{-1}$)")
    ax4.set_title(f"NEON {args.site}: complementarity plane (diagnostic b)")
    ax4.legend(frameon=True)
    fig4.tight_layout()
    f4 = outdir / "fig_neon_complementarity_plane_b.png"
    fig4.savefig(f4)
    plt.close(fig4)

    # Report
    print("\n--- Figures written ---")
    for p in [f1, f2, f3, f4]:
        print(p)

    return 0

if __name__ == "__main__":
    sys.exit(main())